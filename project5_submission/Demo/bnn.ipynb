{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec23f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import MMIO\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc8c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_MNIST:\n",
    "\n",
    "    def __init__(self, batch_size=64):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        ## for sw\n",
    "        self.sign = lambda x: float(1) if x>0 else float(-1)\n",
    "        self.sign = np.vectorize(self.sign)\n",
    "\n",
    "        self.quantize = lambda x: float(0) if x == 1 else float(1)\n",
    "        self.quantize = np.vectorize(self.quantize)\n",
    "\n",
    "        self.adj = lambda x: x*2-1\n",
    "        self.adj = np.vectorize(self.adj)\n",
    "        self.model = np.load(\"weights/model.npy\", allow_pickle=True).item()\n",
    "        # print(model.keys)\n",
    "        # dict_keys(['fc1w', 'fc2w', 'fc3w'])\n",
    "\n",
    "        self.fc1w_q = self.sign(np.array(self.model['fc1w']))\n",
    "        # (128, 784)\n",
    "        self.fc2w_q = self.sign(np.array(self.model['fc2w']))\n",
    "        # (64, 128)\n",
    "        self.fc3w_q = self.sign(np.array(self.model['fc3w']))\n",
    "\n",
    "        self.fc1w_qntz = self.quantize(self.fc1w_q)\n",
    "        self.fc2w_qntz = self.quantize(self.fc2w_q)\n",
    "        self.fc3w_qntz = self.quantize(self.fc3w_q)\n",
    "\n",
    "    def feed_forward(self, input):\n",
    "        \"\"\"This BNN using normal MAC.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        X0_q = self.sign(self.adj(input))\n",
    "\n",
    "        X1 = np.matmul(X0_q, self.fc1w_q.T)\n",
    "\n",
    "        X1_q = self.sign(X1)\n",
    "\n",
    "        X2 = np.matmul(X1_q, self.fc2w_q.T)\n",
    "\n",
    "        X2_q = self.sign(X2)\n",
    "\n",
    "        X3 = np.matmul(X2_q, self.fc3w_q.T)\n",
    "        return X3\n",
    "\n",
    "    def XNOR(self, a, b):\n",
    "        if (a == b):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def matmul_xnor(self, A, B):\n",
    "        \"\"\"This function calcualtes matrix multiplication between two vectors using XNOR.\n",
    "        This function specifically designed for the current network size of 128, 64 and 10 neuron layers.\n",
    "\n",
    "        :param A: The first quantized vector\n",
    "        :param B: The second quantized  vector\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        a, b = B.shape\n",
    "\n",
    "        res = np.zeros(b)\n",
    "\n",
    "        A1 = A.astype(int)\n",
    "        B1 = B.astype(int)\n",
    "\n",
    "        for x in range(b):\n",
    "            cnt = 0\n",
    "            for y in range(a):\n",
    "                # cnt = cnt + A[0][y]*B[y][x]\n",
    "                if a == 784:\n",
    "                    cnt = cnt + self.XNOR(A1[0][y], B1[y][x])\n",
    "\n",
    "                elif a == 128 or a == 64:\n",
    "                    cnt = cnt + self.XNOR(A1[y], B1[y][x])  # XNOR\n",
    "\n",
    "            res[x] = cnt\n",
    "        return res\n",
    "\n",
    "    def matmul_vs_xnormatmul(self):\n",
    "        \"\"\" This is a toy example that demonstrates how to\n",
    "        multiply two binary vectors using XNOR and popcount\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        a = np.array([10, -10, -5, 9, -8, 2, 3, 1, -11])\n",
    "        b = np.array([12, -18, -13, -13, -14, -15, 11, 12, 13])\n",
    "\n",
    "        a = self.sign(a)\n",
    "        b = self.sign(b)\n",
    "\n",
    "        matmul_result = np.matmul(a, b)\n",
    "\n",
    "        # XNOR matmul\n",
    "        a = self.quantize(a)\n",
    "        b = self.quantize(b)\n",
    "\n",
    "        xnormatmul_sum = 0\n",
    "        for x in range(len(a)):\n",
    "            # Doing XNOR and popcount\n",
    "            xnormatmul_sum = xnormatmul_sum + self.XNOR(a[x], b[x])\n",
    "\n",
    "        print(\"Matmul result: {}, XNOR result: {}\".\n",
    "              format(matmul_result, 2*xnormatmul_sum-len(a)))\n",
    "\n",
    "    def pack(self, A, n):\n",
    "        \"\"\"Helper function\n",
    "        :param A:\n",
    "        :param n:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        A_bit = np.array([0] * (n // 32), dtype=np.uint32)\n",
    "\n",
    "        A_lin = np.reshape(A, (n,))\n",
    "\n",
    "        for i in range(0, n, 32):\n",
    "            A_bit[i // 32] = self.concat4(A_lin, i)\n",
    "\n",
    "        return A_bit\n",
    "\n",
    "    def quantize_scale(self, x):\n",
    "        \"\"\"Helper function\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if x == -1:\n",
    "            return 1\n",
    "        elif x == 1:\n",
    "            return 0\n",
    "\n",
    "    def concat4(self, li, point):\n",
    "        \"\"\"Helper function\n",
    "        :param li:\n",
    "        :param point:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        result = np.array([self.quantize_scale(li[point])], dtype=np.uint32)[0].astype(np.uint32)\n",
    "\n",
    "        for k in range(1, 32):\n",
    "            i = point + k\n",
    "            result <<= 1\n",
    "            result &= 0xFFFFFFFF\n",
    "            result |= self.quantize_scale(li[i])\n",
    "            result &= 0xFFFFFFFF\n",
    "        return result.astype(np.uint32)\n",
    "\n",
    "    def preprocessModel(self, X, y):\n",
    "        \"\"\"Helper function\n",
    "        :param X:\n",
    "        :param y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        sample = 2\n",
    "        numpydict = {\"X\": [], \"y\": []}\n",
    "\n",
    "        X0_q = np.array([list(arr) + [1] * 16 for arr in X])\n",
    "\n",
    "        X0_bit = self.pack(X0_q, X0_q.shape[0] * X0_q.shape[1])\n",
    "        Y0 = y\n",
    "        numpydict[\"X\"].append(X0_bit)\n",
    "        numpydict[\"y\"].append(Y0)\n",
    "\n",
    "        np.save('dataset/mnist-bit_sample{}.npy'.format(sample), numpydict, allow_pickle=True)\n",
    "\n",
    "    def create_input(self, num_of_samples):\n",
    "        \"\"\"This function creates packed weights for a given number of samples.\n",
    "        The created inputs are used for HLS tesbench.\n",
    "\n",
    "        :param num_of_samples:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        mnist = np.load(\"dataset/mnist_test_data_original.npy\", allow_pickle=True)\n",
    "        X = mnist.item().get(\"data\")\n",
    "        y = mnist.item().get(\"label\")\n",
    "\n",
    "        X = np.reshape(X, (10000, 784))\n",
    "\n",
    "        if num_of_samples == 0:\n",
    "            num_of_samples = (len(X) // self.batch_size)\n",
    "\n",
    "        numpydict = {\"X\": [], \"y\": []}\n",
    "\n",
    "        for idx in range(num_of_samples):\n",
    "            xs = X[self.batch_size * idx:self.batch_size * idx + self.batch_size]\n",
    "            ys = y[self.batch_size * idx:self.batch_size * idx + self.batch_size]\n",
    "\n",
    "            X0_q = self.sign(self.adj(xs))\n",
    "            self.preprocessModel(X0_q, ys)\n",
    "\n",
    "            X0_q = np.array([list(arr) + [1] * 16 for arr in X0_q])\n",
    "\n",
    "            X0_bit = self.pack(X0_q, X0_q.shape[0] * X0_q.shape[1])\n",
    "            Y0 = ys\n",
    "            numpydict[\"X\"].append(X0_bit)\n",
    "            numpydict[\"y\"].append(Y0)\n",
    "\n",
    "        np.save('dataset/mnist-bit_sample{}.npy'.format(num_of_samples), numpydict, allow_pickle=True)\n",
    "\n",
    "    def create_packed_weights(self):\n",
    "        \"\"\"Helper function: This function creates packed weights for HLS.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        fc1w_q = np.array([list(arr) + ([0] * 16) for arr in self.fc1w_qntz])\n",
    "        fc1w_bit = self.pack(fc1w_q.T.T, fc1w_q.shape[0] * fc1w_q.shape[1])\n",
    "        fc1w_bit = self.pack(fc1w_q, fc1w_q.shape[0] * fc1w_q.shape[1])\n",
    "\n",
    "        fc2w_q = self.fc2w_qntz\n",
    "        fc2w_bit = self.pack(fc2w_q, fc2w_q.shape[0] * fc2w_q.shape[1])\n",
    "\n",
    "        fc3w_q = self.fc3w_qntz\n",
    "        fc3w_bit = self.pack(fc3w_q, fc3w_q.shape[0] * fc3w_q.shape[1])\n",
    "\n",
    "        np.savetxt('weights/layer1.txt', fc1w_bit)\n",
    "        np.savetxt('weights/layer2.txt', fc2w_bit)\n",
    "        np.savetxt('weights/layer3.txt', fc3w_bit)\n",
    "\n",
    "        return fc1w_bit, fc2w_bit, fc3w_bit\n",
    "\n",
    "    def write_to_file(self, w1, w2, w3):\n",
    "        \"\"\" Helper function\n",
    "        :param w1:\n",
    "        :param w2:\n",
    "        :param w3:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Writing to file\n",
    "        with open(\"weights/layer1_c.txt\", \"w\") as file1:\n",
    "            # Writing data to a file\n",
    "            for x in range(len(w1)):\n",
    "                file1.writelines(str(w1[x])+\",\")\n",
    "\n",
    "        with open(\"weights/layer2_c.txt\", \"w\") as file1:\n",
    "            # Writing data to a file\n",
    "            for x in range(len(w2)):\n",
    "                file1.writelines(str(w2[x])+\",\")\n",
    "\n",
    "        with open(\"weights/layer3_c.txt\", \"w\") as file1:\n",
    "            # Writing data to a file\n",
    "            for x in range(len(w3)):\n",
    "                file1.writelines(str(w3[x])+\",\")\n",
    "\n",
    "    def hlscode(self):\n",
    "        \"\"\"This is a reference implementation for HLS.\n",
    "        Intentionally, left empty so that students implement the HLS ref design.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        \n",
    "        ol=Overlay('./design_1_wrapper.bit') #Change name of bitstream as required\n",
    "        ol?\n",
    "        \n",
    "        print(\"Done\")\n",
    "\n",
    "    def feed_forward_quantized(self, input):\n",
    "        \"\"\"This function does BNN. Uses XNOR.\n",
    "\n",
    "        :param input: MNIST sample input\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # layer 1\n",
    "        X0_input = self.quantize(self.sign(self.adj(input)))\n",
    "        layer1_output = self.matmul_xnor(X0_input, self.fc1w_qntz.T)\n",
    "        layer1_activations = (layer1_output * 2 - 784)\n",
    "\n",
    "        # layer 2\n",
    "        layer2_input = self.sign(layer1_activations)\n",
    "        layer2_quantized = self.quantize(layer2_input)\n",
    "        layer2_output = self.matmul_xnor(layer2_quantized, self.fc2w_qntz.T)\n",
    "        layer2_activations = (layer2_output * 2 - 128)\n",
    "\n",
    "        # layer 3\n",
    "        layer3_input = self.sign(layer2_activations)\n",
    "        layer3_quantized = self.quantize(layer3_input)\n",
    "        layer3_output = self.matmul_xnor(layer3_quantized, self.fc3w_qntz.T)\n",
    "\n",
    "        final_output = (layer3_output * 2 - 64)\n",
    "        A = np.array([final_output], np.int32)\n",
    "\n",
    "        return A\n",
    "\n",
    "    def visualize(self, data, true_label, predicated_label):\n",
    "        \"\"\"This function prints image, true label and predicted label.\n",
    "\n",
    "        :param data:\n",
    "        :param true_label:\n",
    "        :param predicated_label:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Visualization\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        # Import the matplotlib.pyplot module for visualization purposes\n",
    "\n",
    "        plt.imshow(data, cmap='gray')\n",
    "        # Display the image at index 0 from the train_data dataset using imshow()\n",
    "        # The cmap='gray' argument specifies that the image should be displayed in grayscale\n",
    "\n",
    "        plt.title(\"true label: {}, predicted label :{}\".format(true_label, predicated_label))\n",
    "        # Set the title of the plot to the label/target corresponding to the image at index 0\n",
    "        # The '%i' is a placeholder that will be replaced by the value of train_data.targets[0]\n",
    "\n",
    "        plt.show()\n",
    "        # Display the plot\n",
    "\n",
    "    def run_test_visalize(self, num_samples):\n",
    "        \"\"\"This function is for debugging. Used for visualizing\n",
    "        the input (MNIST image), the predicted output and the true output.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        mnist = np.load(\"dataset/mnist_test_data_original.npy\", allow_pickle=True)\n",
    "        X = mnist.item().get(\"data\")\n",
    "        y = mnist.item().get(\"label\")\n",
    "\n",
    "        # self.visualize(X[0], y[0], y[0])\n",
    "        X = np.reshape(X, (10000, 784))\n",
    "        print(X.shape)\n",
    "\n",
    "        for idx in range(num_samples):\n",
    "            xs = X[idx]\n",
    "            ys = y[idx]\n",
    "            outputs = self.feed_forward(xs)\n",
    "            xs_plot = np.reshape(xs, (28, 28))\n",
    "            self.visualize(xs_plot, ys, np.argmax(outputs))\n",
    "\n",
    "    def run_test(self, use_normal_mac=False):\n",
    "        \"\"\"This function is for testing\n",
    "\n",
    "        :param use_normal_mac: Setting this parameter calls self.feed_forward (uses MAC),\n",
    "        otherwise, it calls feed_forward_quantized which uses XNOR\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        prediction = []\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        mnist = np.load(\"dataset/mnist_test_data_original.npy\", allow_pickle=True)\n",
    "        X = mnist.item().get(\"data\")\n",
    "        y = mnist.item().get(\"label\")\n",
    "\n",
    "        # self.visualize(X[0], y[0], y[0])\n",
    "        X = np.reshape(X, (10000, 784))\n",
    "        # X = np.reshape(X, (1000, 144))\n",
    "        print(\"The shape of the input: {}\".format(X.shape))\n",
    "\n",
    "        # mnist = np.load(\"dataset/mnist-original.npy\", allow_pickle=True)\n",
    "        # X = mnist.item().get(\"data\").T\n",
    "        # y = mnist.item().get(\"label\")[0]\n",
    "\n",
    "        if use_normal_mac is True:\n",
    "            inference_function = self.feed_forward\n",
    "        else:\n",
    "            inference_function = self.feed_forward_quantized\n",
    "\n",
    "        for idx in range(len(X) // self.batch_size):\n",
    "        # for idx in range(10):\n",
    "            xs = X[self.batch_size * idx:self.batch_size * idx + self.batch_size]\n",
    "            ys = y[self.batch_size * idx:self.batch_size * idx + self.batch_size]\n",
    "\n",
    "            # outputs = self.feed_forward(xs)\n",
    "            # outputs = self.feed_forward_quantized(xs)\n",
    "            outputs = inference_function(xs)\n",
    "\n",
    "            for output, yk in zip(outputs, ys):\n",
    "                prediction.append(np.argmax(output) == (yk))\n",
    "            i += 1\n",
    "            # print(\"{}th iter\".format(idx))\n",
    "            # print(\"Predicted: {}, True: {}\".format(np.argmax(output), yk))\n",
    "\n",
    "        score = np.mean(prediction) * 100\n",
    "        # print(score)\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcec82ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BNN which uses MAC\n",
      "The shape of the input: (10000, 784)\n",
      "Accuracy: 89.39\n",
      "MAC Runtime: 80.36067414283752\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_option = 2\n",
    "    bnn = BNN_MNIST(batch_size=1)\n",
    "\n",
    "    if run_option == 1:\n",
    "        print(\"Running BNN which uses XNOR\")\n",
    "        start = time.time()\n",
    "        print(\"Accuracy:\", bnn.run_test(use_normal_mac=False))\n",
    "        end = time.time()\n",
    "        print(\"XNOR Runtime:\", end-start)\n",
    "    elif  run_option == 2:\n",
    "        print(\"Running BNN which uses MAC\")\n",
    "        start = time.time()\n",
    "        print(\"Accuracy:\", bnn.run_test(use_normal_mac=True))\n",
    "        end = time.time()\n",
    "        print(\"MAC Runtime:\", end-start)\n",
    "    elif run_option == 3:\n",
    "        print(\"Running BNN for HLS reference\")\n",
    "        start = time.time()\n",
    "        bnn.hlscode()\n",
    "        end = time.time()\n",
    "        print(\"HLS Runtime:\", end-start)\n",
    "    elif run_option == 4:\n",
    "        print(\"Creating packed inputs\")\n",
    "        bnn.create_input(10)\n",
    "    elif run_option == 5:\n",
    "        print(\"Creating packed weights\")\n",
    "        bnn.create_packed_weights()\n",
    "    elif run_option == 6:\n",
    "        print(\"XNOR vector multiplication example\")\n",
    "        bnn.matmul_vs_xnormatmul()\n",
    "    elif run_option == 7:\n",
    "        print(\"BNN test\")\n",
    "        bnn.run_test_visalize(num_samples=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd9345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
